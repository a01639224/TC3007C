{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ypeF9lVmHpBw"
   },
   "source": [
    "<h1>Entrenamiento de un transformer para Q&A</h1>\n",
    "\n",
    "Equipo 5:\n",
    "*   Héctor Manuel Cárdenas Yáñez\n",
    "*   Alejandro Pizarro Chávez\n",
    "*   Diego Rosas\n",
    "*   Fausto Alejandro Palma Cervantes\n",
    "*   Alan Ricardo Vilchis Arceo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TH_YlTXpLA-W"
   },
   "source": [
    "Corpus: Caperucita Roja\n",
    "\n",
    "Cuento de hadas, adaptación de Watty Piper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Objetivo</h2>\n",
    "El objetivo de esta actividad es emplear un modelo preentrenado 'BertForQuestionAnswering' para responder diez preguntas planteadas sobre un corpus elegido por nosotros. En nuestro caso, hemos decidido utilizar el cuento de hadas Caperucita Roja debido a su simplicidad y a que es ampliamente conocido. Buscamos obtener respuestas en español e inglés utilizando el mismo modelo preentrenado, y evaluaremos las diferencias entre las respuestas generadas en ambos idiomas, su coherencia y el impacto en el tamaño del corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementación del código</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhluBNyCMVzv"
   },
   "source": [
    "<h3>Importar bibliotecas y descargar el corpus</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1700176934396,
     "user": {
      "displayName": "Alejandro Pizarro Chávez",
      "userId": "17916521159397527539"
     },
     "user_tz": 360
    },
    "id": "yt86Kq0GarF1",
    "outputId": "018b7d21-aa57-4b76-ef98-652d889bbe20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook, Children's Hour with Red Riding Hood and\n",
      "Other Stories, Edited by Watty Piper\n",
      "\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use it under the terms of the Project Gutenberg License included\n",
      "with this eBook or online at www.gutenberg.org\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Title: Children's Hour with Red Riding Hood and Other Stories\n",
      "\n",
      "Editor: Watty Piper\n",
      "\n",
      "Release Date: March 15, 2004  [eBook #11592]\n",
      "\n",
      "Languag\n"
     ]
    }
   ],
   "source": [
    "# Descargamos nuestro corpus\n",
    "url = \"https://raw.githubusercontent.com/AlejandroPizarroo/Transformer-Q-A-Corpus/main/LITTLE%20RED%20RIDING%20HOOD\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Imprimir una parte del texto\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocesamiento del texto</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el texto en fragmentos mas pequeños\n",
    "max_chunk = 4000  \n",
    "chunks = [text[i:i+max_chunk] for i in range(0, len(text), max_chunk)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizacion del texto\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "inputs = tokenizer(chunks, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definir las preguntas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las preguntas\n",
    "questions = [\n",
    "    \"What color is Little Red Riding Hood's hood?\",\n",
    "    \"Who visits the grandmother before Little Red Riding Hood in the story?\",\n",
    "    \"What does Little Red Riding Hood carry in her basket for her grandmother?\",\n",
    "    \"Who warns Little Red Riding Hood about talking to strangers in the woods?\",\n",
    "    \"Who did the wolf pretend to be when he reached the grandmother's cottage?\",\n",
    "    \"Where did Little Red Riding Hood's grandmother live?\",\n",
    "    \"Who ultimately rescued Little Red Riding Hood from the wolf?\",\n",
    "    \"What observations did Little Red Riding Hood make about the wolf disguised as her grandmother?\",\n",
    "    \"How did the story end for the wolf?\",\n",
    "    \"Who wrote this version of the fairy tale of Little Red Riding Hood?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Entrenamiento del modelo</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')  # Modelo pre-entrenado\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    answers_for_question = []\n",
    "    for i in range(len(chunks)):\n",
    "        input_ids = tokenizer.encode(question, chunks[i], max_length=512, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids)\n",
    "        \n",
    "        start_scores = output.start_logits\n",
    "        end_scores = output.end_logits\n",
    "        \n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        # Filtrar los tokens especiales [SEP] y [CLS] de la respuesta\n",
    "        answer_tokens = all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores) + 1]\n",
    "        answer_tokens = [token for token in answer_tokens if token not in ['[CLS]', '[SEP]']]\n",
    "        \n",
    "        answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "        answers_for_question.append(answer.strip())\n",
    "    \n",
    "    # Unir las respuestas de los fragmentos en una sola respuesta para la pregunta\n",
    "    final_answer = ' '.join(answers_for_question)\n",
    "    answers.append(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 870411,
     "status": "ok",
     "timestamp": 1700187280220,
     "user": {
      "displayName": "Alejandro Pizarro Chávez",
      "userId": "17916521159397527539"
     },
     "user_tz": 360
    },
    "id": "blv1FMUEagpN",
    "outputId": "cb0618c3-d778-49f9-a2f0-3cc54d4bd029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What color is Little Red Riding Hood's hood?\n",
      "Answer: red wolf.\n",
      "Question: Who visits the grandmother before Little Red Riding Hood in the story?\n",
      "Answer: mother father.\n",
      "Question: What does Little Red Riding Hood carry in her basket for her grandmother?\n",
      "Answer: eggs , butter and cake .\n",
      "Question: Who warns Little Red Riding Hood about talking to strangers in the woods?\n",
      "Answer: mother .\n",
      "Question: Who did the wolf pretend to be when he reached the grandmother's cottage?\n",
      "Answer:  little red riding hood.\n",
      "Question: Where did Little Red Riding Hood's grandmother live?\n",
      "Answer: at the further end of the wood was another pretty cottage the cottage.\n",
      "Question: Who ultimately rescued Little Red Riding Hood from the wolf?\n",
      "Answer:  little red riding hood ' s father.\n",
      "Question: What observations did Little Red Riding Hood make about the wolf disguised as her grandmother?\n",
      "Answer:  everybody was happy that little red riding hood had escaped the wolf.\n",
      "Question: How did the story end for the wolf?\n",
      "Answer:  chopped off mr .\n",
      "Question: Who wrote this version of the fairy tale of Little Red Riding Hood?\n",
      "Answer: watty piper .\n"
     ]
    }
   ],
   "source": [
    "# Imprimir respuestas\n",
    "for i, answer in enumerate(answers):\n",
    "    print(f\"Question: {questions[i]}\")\n",
    "    # Imprimir solo la primera oración como respuesta\n",
    "    sentences = answer.split('.')\n",
    "    print(f\"Answer: {sentences[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Obtener las respuestas de esas 10 preguntas en español e inglés</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las preguntas\n",
    "questions = [\n",
    "    \"What color is Little Red Riding Hood's hood?\",\n",
    "    \"Who visits the grandmother before Little Red Riding Hood in the story?\",\n",
    "    \"What does Little Red Riding Hood carry in her basket for her grandmother?\",\n",
    "    \"Who warns Little Red Riding Hood about talking to strangers in the woods?\",\n",
    "    \"Who did the wolf pretend to be when he reached the grandmother's cottage?\",\n",
    "    \"Where did Little Red Riding Hood's grandmother live?\",\n",
    "    \"Who ultimately rescued Little Red Riding Hood from the wolf?\",\n",
    "    \"What observations did Little Red Riding Hood make about the wolf disguised as her grandmother?\",\n",
    "    \"How did the story end for the wolf?\",\n",
    "    \"Who wrote this version of the fairy tale of Little Red Riding Hood?\",\n",
    "    \"¿De qué color es el capuchón de Caperucita Roja?\",\n",
    "    \"¿Quién visita a la abuelita antes que Caperucita Roja en la historia?\",\n",
    "    \"¿Qué lleva Caperucita Roja en su cesta para su abuela?\",\n",
    "    \"¿Quién advierte a Caperucita Roja sobre hablar con extraños en el bosque?\",\n",
    "    \"¿A quién fingió ser el lobo cuando llegó a la cabaña de la abuelita?\",\n",
    "    \"¿Dónde vivía la abuela de Caperucita Roja?\",\n",
    "    \"¿Quién finalmente rescató a Caperucita Roja del lobo?\",\n",
    "    \"¿Qué observaciones hizo Caperucita Roja sobre el lobo disfrazado como su abuela?\",\n",
    "    \"¿Cómo terminó la historia para el lobo?\",\n",
    "    \"¿Quién escribió esta versión del cuento de hadas de Caperucita Roja?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')  # Modelo pre-entrenado\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    answers_for_question = []\n",
    "    for i in range(len(chunks)):\n",
    "        input_ids = tokenizer.encode(question, chunks[i], max_length=512, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids)\n",
    "        \n",
    "        start_scores = output.start_logits\n",
    "        end_scores = output.end_logits\n",
    "        \n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        # Filtrar los tokens especiales [SEP] y [CLS] de la respuesta\n",
    "        answer_tokens = all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores) + 1]\n",
    "        answer_tokens = [token for token in answer_tokens if token not in ['[CLS]', '[SEP]']]\n",
    "        \n",
    "        answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "        answers_for_question.append(answer.strip())\n",
    "    \n",
    "    # Unir las respuestas de los fragmentos en una sola respuesta para la pregunta\n",
    "    final_answer = ' '.join(answers_for_question)\n",
    "    answers.append(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What color is Little Red Riding Hood's hood?\n",
      "Answer: red wolf.\n",
      "Question: Who visits the grandmother before Little Red Riding Hood in the story?\n",
      "Answer: mother father.\n",
      "Question: What does Little Red Riding Hood carry in her basket for her grandmother?\n",
      "Answer: eggs , butter and cake .\n",
      "Question: Who warns Little Red Riding Hood about talking to strangers in the woods?\n",
      "Answer: mother .\n",
      "Question: Who did the wolf pretend to be when he reached the grandmother's cottage?\n",
      "Answer:  little red riding hood.\n",
      "Question: Where did Little Red Riding Hood's grandmother live?\n",
      "Answer: at the further end of the wood was another pretty cottage the cottage.\n",
      "Question: Who ultimately rescued Little Red Riding Hood from the wolf?\n",
      "Answer:  little red riding hood ' s father.\n",
      "Question: What observations did Little Red Riding Hood make about the wolf disguised as her grandmother?\n",
      "Answer:  everybody was happy that little red riding hood had escaped the wolf.\n",
      "Question: How did the story end for the wolf?\n",
      "Answer:  chopped off mr .\n",
      "Question: Who wrote this version of the fairy tale of Little Red Riding Hood?\n",
      "Answer: watty piper .\n",
      "Question: ¿De qué color es el capuchón de Caperucita Roja?\n",
      "Answer: red .\n",
      "Question: ¿Quién visita a la abuelita antes que Caperucita Roja en la historia?\n",
      "Answer:  everybody was happy that little red riding hood had escaped the wolf .\n",
      "Question: ¿Qué lleva Caperucita Roja en su cesta para su abuela?\n",
      "Answer:  .\n",
      "Question: ¿Quién advierte a Caperucita Roja sobre hablar con extraños en el bosque?\n",
      "Answer:  .\n",
      "Question: ¿A quién fingió ser el lobo cuando llegó a la cabaña de la abuelita?\n",
      "Answer:  .\n",
      "Question: ¿Dónde vivía la abuela de Caperucita Roja?\n",
      "Answer:  everybody was happy that little red riding hood had escaped the wolf .\n",
      "Question: ¿Quién finalmente rescató a Caperucita Roja del lobo?\n",
      "Answer:  .\n",
      "Question: ¿Qué observaciones hizo Caperucita Roja sobre el lobo disfrazado como su abuela?\n",
      "Answer: almost no restrictions .\n",
      "Question: ¿Cómo terminó la historia para el lobo?\n",
      "Answer:  .\n",
      "Question: ¿Quién escribió esta versión del cuento de hadas de Caperucita Roja?\n",
      "Answer:  .\n"
     ]
    }
   ],
   "source": [
    "# Imprimir respuestas\n",
    "for i, answer in enumerate(answers):\n",
    "    print(f\"Question: {questions[i]}\")\n",
    "    # Imprimir solo la primera oración como respuesta\n",
    "    sentences = answer.split('.')\n",
    "    print(f\"Answer: {sentences[0]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Resultados</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Hubo alguna diferencia?\n",
    "* La diferencia que se encuentra entre las preguntas en español e inglés es sumamente evidente. En las preguntas en inglés, el transformer logra contestar de manera correcta o parcialmente correcta nueve de las diez preguntas que se le realizaron. Sin embargo, en las preguntas en español solamente logra contestar de manera correcta la primera pregunta, la cual resulta ser la más sencilla de todas. Es verdad que responde a otras tres preguntas más, pero su respuesta no tiene sentido alguno, y en las otras preguntas simplemente no da una respuesta clara y concisa.\n",
    "  \n",
    "¿Qué lenguaje conviene más y por qué?\n",
    "* En nuestro caso de prueba, el uso del idioma inglés resulta mucho más conveniente, principalmente debido al modelo que empleamos: el modelo 'bert-large-uncased-whole-word-masking-finetuned-squad', el cual se basa en BERT (Bidirectional Encoder Representations from Transformers) y está preentrenado en inglés. Esta es la razón principal por la que buscamos un corpus en inglés, para que fuera coherente con el modelo preentrenado que seleccionamos. Esto se puede evidenciar en los resultados obtenidos de las preguntas formuladas tanto en español como en inglés.\n",
    "\n",
    "¿Cuál era el tamaño del corpus?\n",
    "* El corpus consta de 741 palabras y 4,230 caracteres. Es importante mencionar que elegimos  un corpus significativamente más pequeño. En las pruebas iniciales, habíamos optado por un corpus más extenso y complejo, pero nos enfrentamos a resultados extremadamente lentos de obtener. Además, carecían por completo de coherencia ya que mientras más complejo era el libro, menos sentido tenían las respuestas que obteníamos. Los corpus que probamos anteriormente fueron 'La Metamorfosis' de Franz Kafka y 'Rebelión en la Granja' de George Orwell.\n",
    "\n",
    "¿Cuántas respuestas tienen coherencia?\n",
    "* De las diez preguntas formuladas en inglés, nueve muestran coherencia y tienen una respuesta correcta o parcialmente correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cambio de corpus, mismas preguntas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Project Gutenberg Australia\n",
      "\n",
      "\n",
      "\n",
      "Title:      Animal Farm\n",
      "Author:     George Orwell (pseudonym of Eric Blair) (1903-1950)\n",
      "* A Project Gutenberg of Australia eBook *\n",
      "eBook No.:  0100011.txt\n",
      "Language:   English\n",
      "Date first posted:          August 2001\n",
      "Date most recently updated: March 2008\n",
      "\n",
      "Project Gutenberg of Australia eBooks are created from printed editions\n",
      "which are in the public domain in Australia, unless a copyright notice\n",
      "is included. We do NOT keep any eBooks in compliance with a particula\n"
     ]
    }
   ],
   "source": [
    "# Descargamos nuestro corpus\n",
    "url = \"https://gutenberg.net.au/ebooks01/0100011.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "# Imprimir una parte del texto\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el texto en fragmentos mas pequeños\n",
    "max_chunk = 4000  \n",
    "chunks = [text[i:i+max_chunk] for i in range(0, len(text), max_chunk)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las preguntas\n",
    "questions = [\n",
    "    \"What color is Little Red Riding Hood's hood?\",\n",
    "    \"Who visits the grandmother before Little Red Riding Hood in the story?\",\n",
    "    \"What does Little Red Riding Hood carry in her basket for her grandmother?\",\n",
    "    \"Who warns Little Red Riding Hood about talking to strangers in the woods?\",\n",
    "    \"Who did the wolf pretend to be when he reached the grandmother's cottage?\",\n",
    "    \"Where did Little Red Riding Hood's grandmother live?\",\n",
    "    \"Who ultimately rescued Little Red Riding Hood from the wolf?\",\n",
    "    \"What observations did Little Red Riding Hood make about the wolf disguised as her grandmother?\",\n",
    "    \"How did the story end for the wolf?\",\n",
    "    \"Who wrote this version of the fairy tale of Little Red Riding Hood?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')  # Modelo pre-entrenado\n",
    "answers = []\n",
    "\n",
    "for question in questions:\n",
    "    answers_for_question = []\n",
    "    for i in range(len(chunks)):\n",
    "        input_ids = tokenizer.encode(question, chunks[i], max_length=512, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids)\n",
    "        \n",
    "        start_scores = output.start_logits\n",
    "        end_scores = output.end_logits\n",
    "        \n",
    "        all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        # Filtrar los tokens especiales [SEP] y [CLS] de la respuesta\n",
    "        answer_tokens = all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores) + 1]\n",
    "        answer_tokens = [token for token in answer_tokens if token not in ['[CLS]', '[SEP]']]\n",
    "        \n",
    "        answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
    "        answers_for_question.append(answer.strip())\n",
    "    \n",
    "    # Unir las respuestas de los fragmentos en una sola respuesta para la pregunta\n",
    "    final_answer = ' '.join(answers_for_question)\n",
    "    answers.append(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What color is Little Red Riding Hood's hood?\n",
      "Answer:                                           .\n",
      "Question: Who visits the grandmother before Little Red Riding Hood in the story?\n",
      "Answer:                                           .\n",
      "Question: What does Little Red Riding Hood carry in her basket for her grandmother?\n",
      "Answer:                                           .\n",
      "Question: Who warns Little Red Riding Hood about talking to strangers in the woods?\n",
      "Answer:                                           .\n",
      "Question: Who did the wolf pretend to be when he reached the grandmother's cottage?\n",
      "Answer:                                           .\n",
      "Question: Where did Little Red Riding Hood's grandmother live?\n",
      "Answer:                                           .\n",
      "Question: Who ultimately rescued Little Red Riding Hood from the wolf?\n",
      "Answer:       .      who ultimately rescued little red riding hood from the wolf ? as they imagined , their enemies in flight , and they rushed after them in disorder . this was just what snowball had intended . as soon as they were well inside the yard , the three horses , the three cows , and the rest of the pigs , who had been lying in ambush in the cowshed , suddenly emerged in their rear , cutting them off . snowball now gave the signal for the charge .\n",
      "Question: What observations did Little Red Riding Hood make about the wolf disguised as her grandmother?\n",
      "Answer:                                           .\n",
      "Question: How did the story end for the wolf?\n",
      "Answer:       .                                    .\n",
      "Question: Who wrote this version of the fairy tale of Little Red Riding Hood?\n",
      "Answer: eric blair            snowball                              .\n"
     ]
    }
   ],
   "source": [
    "# Imprimir respuestas\n",
    "for i, answer in enumerate(answers):\n",
    "    print(f\"Question: {questions[i]}\")\n",
    "    # Imprimir solo la primera oración como respuesta\n",
    "    sentences = answer.split('.')\n",
    "    print(f\"Answer: {'.'.join(sentences[:5])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Si cambia el corpus y pregunta lo mismo recibirá una respuesta? Demuestre\r",
    "* Después de cambiar el corpus y realizar las mismas preguntas, descubrimos que de las diez, solo se pueden responder dos, y estas carecen de sentido alguno. En la pregunta siete, se intenta desarrollar una idea, pero al final, el texto carece de coherencia, pareciendo simplemente tomar un fragmento del corpus. Es importante mencionar que se limitó la salida de las respuestas para mantener la legibilidad, lo que nos deja solo con las primeras ideas. No obstante, esto proporciona suficiente evidencia para determinar que el modelo preentrenado no puede responder preguntas sobre el cuento de hadas Caperucita Roja cuando se utiliza un corpus de 'Rebelión en la Granja' de George Orwell.\n",
    "\n",
    "¿Cuántos lenguajes puede manejar el BERT para resolver preguntas?\n",
    "* BERT puede entender y procesar preguntas en más de 100 idiomas diferentes, aunque su entrenamiento principal se llevó a cabo en inglés. Es importante mencionar que al menos en nuestra demostración recomendaría hacer las preguntas en el mismo idioma en el que está el corpus ya que de esta manera se obtienen resultados más coherentes y precisos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusiones</h2>\n",
    "Tras realizar múltiples pruebas con el modelo preentrenado BERT, hemos descubierto que constituye una práctica excelente para el desarrollo de un transformer de preguntas y respuestas (Q&A). Si bien es cierto que hoy en día estamos acostumbrados a herramientas como ChatGPT, que nos ofrecen respuestas más precisas y coherentes gracias a su sofisticación, BERT, siendo un modelo más básico, puede proporcionar resultados aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMGP38xQmlQ2AzI82Pz0qSH",
   "mount_file_id": "1Cc6Q_D7mnq3BU6Ki8J_mXHAOjO7BQ80O",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
